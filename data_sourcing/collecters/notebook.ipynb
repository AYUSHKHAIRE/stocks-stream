{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushkhaire/real-time-data-update?scriptVersionId=224095536\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"77be023b","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-02-23T17:12:23.174763Z","iopub.status.busy":"2025-02-23T17:12:23.173864Z","iopub.status.idle":"2025-02-23T17:12:25.27431Z","shell.execute_reply":"2025-02-23T17:12:25.273135Z"},"papermill":{"duration":2.115624,"end_time":"2025-02-23T17:12:25.276859","exception":false,"start_time":"2025-02-23T17:12:23.161235","status":"completed"},"tags":[]},"outputs":[],"source":["import requests as rq\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","from datetime import datetime\n","import time \n","from tqdm import tqdm\n","import os\n","from datetime import datetime,timedelta\n","from pymongo.mongo_client import MongoClient\n","from pymongo.server_api import ServerApi\n","import logging\n","from kaggle_secrets import UserSecretsClient\n","import warnings\n","import json\n","import shutil\n","import subprocess\n","import gc\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"f8137f6e","metadata":{"papermill":{"duration":0.005864,"end_time":"2025-02-23T17:12:25.288954","exception":false,"start_time":"2025-02-23T17:12:25.28309","status":"completed"},"tags":[]},"source":["# Configuration"]},{"cell_type":"code","execution_count":2,"id":"d478a31e","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:25.303913Z","iopub.status.busy":"2025-02-23T17:12:25.303005Z","iopub.status.idle":"2025-02-23T17:12:25.309789Z","shell.execute_reply":"2025-02-23T17:12:25.308476Z"},"papermill":{"duration":0.016984,"end_time":"2025-02-23T17:12:25.312197","exception":false,"start_time":"2025-02-23T17:12:25.295213","status":"completed"},"tags":[]},"outputs":[],"source":["logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(message)s\")\n","logger = logging.getLogger(__name__)\n","\n","\n","logger.info(\"This is an INFO message\")"]},{"cell_type":"markdown","id":"5080b61e","metadata":{"papermill":{"duration":0.006284,"end_time":"2025-02-23T17:12:25.324566","exception":false,"start_time":"2025-02-23T17:12:25.318282","status":"completed"},"tags":[]},"source":["# Secrets"]},{"cell_type":"code","execution_count":3,"id":"de252e7e","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:25.338856Z","iopub.status.busy":"2025-02-23T17:12:25.338409Z","iopub.status.idle":"2025-02-23T17:12:26.416744Z","shell.execute_reply":"2025-02-23T17:12:26.415792Z"},"papermill":{"duration":1.087743,"end_time":"2025-02-23T17:12:26.419111","exception":false,"start_time":"2025-02-23T17:12:25.331368","status":"completed"},"tags":[]},"outputs":[],"source":["user_secrets = UserSecretsClient()\n","kaggle_apikey = user_secrets.get_secret(\"kaggle_apikey\")\n","kaggle_username = user_secrets.get_secret(\"kaggle_username\")\n","mngodb_database_name = user_secrets.get_secret(\"mngodb_database_name\")\n","mongodb_app_name = user_secrets.get_secret(\"mongodb_appname\")\n","mongodb_password = user_secrets.get_secret(\"mongodb_password\")\n","mongodb_username = user_secrets.get_secret(\"mongodb_username\")\n","mongodb_cluster_name = user_secrets.get_secret(\"mongodb_cluster_name\")"]},{"cell_type":"markdown","id":"c29df6b7","metadata":{"papermill":{"duration":0.006826,"end_time":"2025-02-23T17:12:26.432454","exception":false,"start_time":"2025-02-23T17:12:26.425628","status":"completed"},"tags":[]},"source":["# MongoDB"]},{"cell_type":"code","execution_count":4,"id":"111e7a41","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:26.445851Z","iopub.status.busy":"2025-02-23T17:12:26.445463Z","iopub.status.idle":"2025-02-23T17:12:26.459519Z","shell.execute_reply":"2025-02-23T17:12:26.457651Z"},"papermill":{"duration":0.0237,"end_time":"2025-02-23T17:12:26.461984","exception":false,"start_time":"2025-02-23T17:12:26.438284","status":"completed"},"tags":[]},"outputs":[],"source":["class AtlasClient:\n","    def __init__(self, atlas_uri, dbname):\n","        self.mongodb_client = MongoClient(atlas_uri)\n","        self.database = self.mongodb_client[dbname]\n","\n","    def ping(self):\n","        try:\n","            self.mongodb_client.admin.command('ping')\n","            logging.info(\"Pinged your MongoDB deployment. Connection successful.\")\n","        except Exception as e:\n","            logging.error(f\"Failed to connect to MongoDB: {e}\")\n","\n","    def get_collection(self, collection_name):\n","        collection = self.database[collection_name]\n","        return collection\n","\n","    def findOneByKey(self,collection_name,key):\n","        collection = self.get_collection(collection_name)\n","        result = collection.find_one({ key: { \"$exists\": True } })\n","        return result\n","\n","\n","    def find(self, collection_name, filter={}, limit=0):\n","        collection = self.database[collection_name]\n","        items = list(collection.find(filter=filter, limit=limit))\n","        return items\n","    \n","    def insert(self, collection_name, documents):\n","        \"\"\"\n","        Inserts one or more documents into a MongoDB collection.\n","        \n","        Parameters:\n","        - collection_name: str, the name of the collection\n","        - documents: dict or list of dicts, the document(s) to insert\n","        \n","        If `documents` is a list, it will insert multiple documents using `insert_many`.\n","        Otherwise, it will insert a single document using `insert_one`.\n","        \"\"\"\n","        collection = self.get_collection(collection_name)\n","        \n","        if isinstance(documents, list):\n","            result = collection.insert_many(documents)\n","            return result.inserted_ids\n","        else:\n","            result = collection.insert_one(documents)\n","            return result.inserted_id\n","        \n","    def delete(self, collection_name, filter={}, _del_all_=False):\n","        \"\"\"\n","        Deletes documents from a MongoDB collection based on the filter.\n","        \n","        Parameters:\n","        - collection_name: str, the name of the collection.\n","        - filter: dict, the filter to find documents to delete (default is {}).\n","        - _del_all_: bool, if True, deletes all documents matching the filter using `delete_many()`.\n","                      If False, deletes only one document using `delete_one()`.\n","        \n","        Returns:\n","        - Number of documents deleted.\n","        \"\"\"\n","        collection = self.get_collection(collection_name)\n","        \n","        if _del_all_:\n","            result = collection.delete_many(filter)\n","            return result.deleted_count\n","        else:\n","            result = collection.delete_one(filter)\n","            if result.deleted_count == 1:\n","                pass\n","            else:\n","                pass\n","            return result.deleted_count"]},{"cell_type":"markdown","id":"930293f9","metadata":{"papermill":{"duration":0.006201,"end_time":"2025-02-23T17:12:26.47412","exception":false,"start_time":"2025-02-23T17:12:26.467919","status":"completed"},"tags":[]},"source":["# Stocks manager"]},{"cell_type":"code","execution_count":5,"id":"89aebc98","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:26.488793Z","iopub.status.busy":"2025-02-23T17:12:26.488354Z","iopub.status.idle":"2025-02-23T17:12:26.662678Z","shell.execute_reply":"2025-02-23T17:12:26.660906Z"},"papermill":{"duration":0.184829,"end_time":"2025-02-23T17:12:26.665465","exception":false,"start_time":"2025-02-23T17:12:26.480636","status":"completed"},"tags":[]},"outputs":[],"source":["AC = AtlasClient(\n","    atlas_uri=f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_cluster_name}.fznbh.mongodb.net/?retryWrites=true&w=majority&appName={mongodb_app_name}\",\n","    dbname = mngodb_database_name\n",")\n","\n","\n","class stocksManager:\n","    def __init__(self) -> None:\n","        self.available_stocks = []\n","        headers = {\n","            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n","        }\n","        self.headers = headers\n","        self.firstrun = 0\n","\n","    def collect_stock_symbols(self):\n","        targets = [\n","            '52-week-gainers', \n","            '52-week-losers'\n","        ]   \n","    \n","        limitlist = []\n","\n","        for page in tqdm(targets):\n","            url = f'https://finance.yahoo.com/markets/stocks/{page}/?start=0&count=100'\n","            # print(url)\n","            try:\n","                r = rq.get(url,headers = self.headers)\n","            except Exception as e:\n","                logger.warning(\"cannot hit url : \",url ,e,r.status_code)\n","            soup = BeautifulSoup(r.text,'html.parser')\n","            limits = soup.find(\n","                'div',{'class':'total'}\n","            ).text\n","            limits = limits.split(' ')[2]\n","            limitlist.append(limits)\n","\n","        max_hits = []\n","        for limit in limitlist:\n","            max_hit = int(int(limit) / 100)\n","            max_hits.append(max_hit)\n","\n","        findict = {\n","            'targets':targets,\n","            'max_hits':max_hits\n","        }\n","        \n","        urls_for_stocks = []\n","\n","        i = 0\n","        for i in range(\n","            len(\n","                findict['targets']\n","                )\n","            ):\n","            target = findict['targets'][i]\n","            maxhit = findict['max_hits'][i]\n","            for m in range(maxhit+1):\n","                url = f'https://finance.yahoo.com/markets/stocks/{target}/?start={m*100}&count=100/'\n","                urls_for_stocks.append(url)\n","\n","        data = []\n","\n","        logger.info('collecting data for symbols _______________________________--')\n","        for u in urls_for_stocks:\n","            catg = u.split('/')[-3]\n","            symbol_list = []\n","            try:\n","                r = rq.get(u,headers = self.headers)\n","            except Exception as e:\n","                logger.warning(\"cannot hit url : \",u ,r.status_code)\n","            soup = BeautifulSoup(r.text,'html.parser')\n","            symbs= soup.find_all('span',{'class':'symbol'})\n","            for s in symbs:\n","                symbol_list.append(s.text)\n","            data.append(\n","                {catg:symbol_list}\n","            )\n","        logger.info(\"finished collecting data for symbols ______________________________-\")\n","        data = {'names':data}\n","        return data\n","    \n","    def return_list_for_symbols(self):\n","        symbols = self.collect_stock_symbols()\n","        finals_symbols = []\n","        for n in symbols['names']:\n","            for key in n.keys():\n","                finals_symbols=finals_symbols+n[key]\n","        finals_symbols = list(set(finals_symbols))\n","        return finals_symbols\n","\n","    def return_human_timestamp(self, timestamps):\n","            if isinstance(timestamps, list):\n","                new_dates = []\n","                for unix_time in timestamps:\n","                    try:\n","                        if isinstance(unix_time, str):\n","                            datetime.strptime(unix_time, '%Y-%m-%d %H:%M:%S') \n","                            new_dates.append(unix_time)\n","                        else:\n","                            unix_time = float(unix_time)\n","                            date = datetime.fromtimestamp(unix_time).strftime('%Y-%m-%d %H:%M:%S')\n","                            new_dates.append(date)\n","                    except (ValueError, TypeError):\n","                        new_dates.append(None)  \n","                return new_dates\n","            elif isinstance(timestamps, str):\n","                try:\n","                    unix_time = float(timestamps)\n","                    date = datetime.fromtimestamp(unix_time).strftime('%Y-%m-%d %H:%M:%S')\n","                    return date\n","                except (ValueError, TypeError):\n","                    return None\n","\n","    def return_unix_timestamps(self, date_strings):\n","        if isinstance(date_strings, list):\n","            unix_timestamps = []\n","            for date_str in date_strings:\n","                try:\n","                    dt = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n","                    unix_timestamp = int(dt.timestamp())  \n","                    unix_timestamps.append(unix_timestamp)\n","                except (ValueError, TypeError):\n","                    unix_timestamps.append(None)\n","            return unix_timestamps\n","        elif isinstance(date_strings, str):\n","            try:\n","                dt = datetime.strptime(date_strings, '%Y-%m-%d %H:%M:%S')\n","                unix_timestamp = int(dt.timestamp())  \n","                return unix_timestamp\n","            except (ValueError, TypeError):\n","                return None\n","\n","    def update_prices_for_daily(self, symbol_list):\n","        current_timestamp = int(time.time())\n","        current_time = datetime.fromtimestamp(current_timestamp)\n","        human_readable_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n","        \n","        # Start and end periods for data retrieval\n","        start_date_str = \"2015-01-01\"\n","        start_date_obj = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n","        period1 = int(time.mktime(start_date_obj.timetuple()))\n","        period2 = current_timestamp\n","        \n","        logger.warning(f\"Daily data for today's date {human_readable_time}\")\n","        logger.info(f\"Checking updates for period1={period1} & period2={period2} for stocks daily\")\n","\n","        # Define base path for daily updates\n","        files_path = f'/kaggle/working/daily_update/'\n","        os.makedirs('/kaggle/working/daily_update/',exist_ok = True)\n","        os.makedirs('/kaggle/working/daily_update_to_kaggle/',exist_ok = True)\n","        AC.delete(\n","            \"daily_data\",\n","            _del_all_ = True\n","        )\n","        for stock in tqdm(symbol_list):\n","            stock_symbol = stock.replace(' ', '')\n","            json_path = f'{files_path}/{stock_symbol}.json'\n","            os.makedirs(os.path.dirname(json_path), exist_ok=True)\n","            \n","            url = (f'https://query1.finance.yahoo.com/v8/finance/chart/{stock_symbol}?events=capitalGain%7Cdiv%7Csplit'\n","                f'&formatted=true&includeAdjustedClose=true&interval=1d&period1={period1}&period2={period2}'\n","                f'&symbol={stock_symbol}&userYfid=true&lang=en-US&region=US')\n","            try:\n","                response = rq.get(url, headers=self.headers)\n","                if response.status_code == 200:\n","                    with open(json_path, 'wb') as file:\n","                        file.write(response.content)\n","                    json_data = pd.read_json(json_path)\n","                    timestamp = json_data['chart']['result'][0].get('timestamp')\n","                    if timestamp:\n","                        new_timestamps = self.return_human_timestamp(timestamp)\n","                        new_data = json_data['chart']['result'][0]['indicators']['quote'][0]\n","                        new_data['timestamp'] = new_timestamps\n","                        data_to_insert = {f'{stock_symbol}':new_data}\n","                        if data_to_insert:\n","#                             in database\n","                            AC.insert(\n","                                collection_name=\"daily_data\",\n","                                documents=data_to_insert\n","                            )\n","#                            local\n","                            new_data = pd.DataFrame(new_data)\n","                            new_data.to_csv(f'/kaggle/working/daily_update_to_kaggle/{stock}.csv')\n","                            \n","                        else:\n","                            logger.error(f'daily data insertion for {stock} failed .',e)\n","                else:\n","                    logger.warning(f\"Request failed: {url}, Status code: {response.status_code}\")\n","                    continue\n","            except:\n","                continue\n","        logger.info(\"Daily data update finished.\")\n","  \n","    \n","    def update_prices_for_per_minute(self, symbol_list,last_date):\n","        os.makedirs(f'/kaggle/working/per_minute/', exist_ok=True)\n","        os.makedirs(f'/kaggle/working/per_minute_to_kaggle/', exist_ok=True) \n","        date_time_obj = datetime.strptime(last_date, '%Y-%m-%d %H:%M:%S')\n","        period1 = int(date_time_obj.timestamp())\n","        seven_days_back = date_time_obj - timedelta(days=7)\n","        period2 = int(seven_days_back.timestamp())\n","  \n","        logger.info(f\"Checking updates for period1={period1} & period2={period2} for stocks per minute.\")\n","            \n","        AC.delete(\n","                collection_name=\"per_minute_data\",\n","                _del_all_ = True\n","        )\n","        if symbol_list:\n","            for stock in tqdm(symbol_list):\n","                try:\n","                    stock_symbol = stock.replace(' ', '')\n","                    link = f'https://query2.finance.yahoo.com/v8/finance/chart/{stock_symbol}?period1={period2}&period2={period1}&interval=1m&includePrePost=true&events=div%7Csplit%7Cearn&&lang=en-US&region=US'\n","                    response = rq.get(link, headers=self.headers)\n","                    tmppath = f'/kaggle/working/per_minute/{stock_symbol}.json'\n","                    if response.status_code == 200:\n","                        with open(tmppath, 'wb') as jsn:\n","                            jsn.write(response.content)\n","                        json_data  = pd.read_json(tmppath)\n","                        timestamp = json_data['chart'][0][0]['timestamp']\n","                        json_data = json_data['chart'][0][0][\"indicators\"][\"quote\"][0]\n","                        try:\n","                            new_timestamps = self.return_human_timestamp(timestamp)\n","                            json_data['timestamp'] = new_timestamps\n","                            data_to_insert = {f'{stock_symbol}':json_data}\n","    #                         to database\n","                            if data_to_insert:\n","                            #    AC.insert(\n","                            #         collection_name=\"per_minute_data\",\n","                            #         documents=data_to_insert\n","                            #    )\n","    #                           to csv\n","                                json_data = pd.DataFrame(json_data)\n","                                json_data.to_csv(f'/kaggle/working/per_minute_to_kaggle/{stock}.csv')\n","                            else:\n","                                logger.warning(f'per minute data insertion data insertion for {stock} failed .'),e\n","\n","                        except Exception as e:\n","                            logger.warning(f\"Request failed: {link}, Status code: {response.status_code}\")\n","                            print('failed',e)\n","                            continue\n","                except:\n","                    continue\n","                \n","        else:\n","            logger.warning(\"It is not Sunday today. Skipping the update step.\")\n","        logger.info(\"Per minute update finished.\")\n","\n","    def update_stocks_list_for_today(self):\n","        AC.delete('master',_del_all_ = True)\n","        stocks = AC.find(\"daily_data\")\n","        stockslist = []\n","        for st in tqdm(stocks):\n","            stockslist.append(list(st.keys())[1])\n","        self.available_stocks = stockslist\n","        AC.insert(\"master\",{'stocks':stockslist})\n","        logger.warning(\"stocks list updated !\")\n","        \n","    # specific to kaggle\n","    def Kaggle_process_daily_data(self,symbol_list):\n","        self.update_prices_for_daily(symbol_list)\n","        megadatadailyframe = pd.DataFrame()\n","        daily_files_csv = os.listdir('/kaggle/working/daily_update_to_kaggle')\n","\n","        for csv in tqdm(daily_files_csv):\n","            df = pd.read_csv(f'/kaggle/working/daily_update_to_kaggle/{csv}')\n","            df['stockname'] = csv.split('.')[0]\n","            megadatadailyframe = pd.concat([megadatadailyframe,df],axis = 0)\n","            \n","        os.makedirs(f'/kaggle/working/daily_update_to_kaggle_final',exist_ok = True)\n","        megadatadailyframe.to_csv('/kaggle/working/daily_update_to_kaggle_final/stocks.csv')\n","    \n","    def Kaggle_process_per_minute_data(self,symbol_list,last_date,weekday):\n","        self.update_prices_for_per_minute(symbol_list,last_date)\n","        megadataperminuteframe = pd.DataFrame()\n","        perminute_files_csv = os.listdir('/kaggle/working/per_minute_to_kaggle/')\n","\n","        for csv in tqdm(perminute_files_csv):\n","            df = pd.read_csv(f'/kaggle/working/per_minute_to_kaggle/{csv}')\n","            df['stockname'] = csv.split('.')[0]\n","            megadataperminuteframe = pd.concat([megadataperminuteframe,df],axis = 0)\n","        os.makedirs(f'/kaggle/working/per_minute_to_kaggle_final',exist_ok = True)\n","        past_df = pd.read_csv(\"/kaggle/input/real-time-stocks-data/stocks.csv\")\n","        megadataperminuteframe = pd.concat([megadataperminuteframe,past_df],axis = 0)\n","        megadataperminuteframe = megadataperminuteframe.drop_duplicates()\n","        megadataperminuteframe = megadataperminuteframe[['low','high','volume','open','close','stockname','timestamp']]\n","        megadataperminuteframe.to_csv('/kaggle/working/per_minute_to_kaggle_final/stocks.csv')"]},{"cell_type":"markdown","id":"9d6af5bc","metadata":{"papermill":{"duration":0.00608,"end_time":"2025-02-23T17:12:26.678089","exception":false,"start_time":"2025-02-23T17:12:26.672009","status":"completed"},"tags":[]},"source":["# Recover data if any lost"]},{"cell_type":"code","execution_count":6,"id":"26483feb","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:26.697568Z","iopub.status.busy":"2025-02-23T17:12:26.697172Z","iopub.status.idle":"2025-02-23T17:12:26.727599Z","shell.execute_reply":"2025-02-23T17:12:26.726269Z"},"papermill":{"duration":0.045222,"end_time":"2025-02-23T17:12:26.730396","exception":false,"start_time":"2025-02-23T17:12:26.685174","status":"completed"},"tags":[]},"outputs":[],"source":["class recoverData:\n","    def __init__(self):\n","        self.symbol_list = None\n","        self.avdata = None\n","        self.headers = {'User-Agent': 'Mozilla/5.0'}\n","        self.batches_to_check = []\n","        self.recoverlist = []\n","\n","    def setup(self):\n","        os.makedirs(\"/kaggle/working/per_minute_recover/json/\", exist_ok=True)\n","        os.makedirs(\"/kaggle/working/per_minute_recover/csv/\", exist_ok=True)\n","        os.makedirs(\"/kaggle/working/per_minute_recover/final/\", exist_ok=True)\n","        print(\"set up directories\")\n","        self.avdata = pd.read_csv('/kaggle/input/real-time-stocks-data/stocks.csv')\n","        self.symbol_list = self.avdata['stockname'].unique()\n","        print(\"stock list and dataset loaded .\")\n","\n","    def return_unix_timestamps(self, date_strings):\n","        try:\n","            dt = datetime.strptime(date_strings, '%Y-%m-%d')\n","            return int(dt.timestamp())\n","        except ValueError:\n","            return None\n","\n","    def return_human_timestamp(self, timestamps):\n","        try:\n","            return [datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S') for ts in timestamps]\n","        except Exception:\n","            return None\n","\n","    def collect_per_minute_data(self, stock_symbol, start_date, end_date):\n","        period1 = start_date\n","        period2 = end_date\n","        if period1 is None or period2 is None:\n","            print(f\"Invalid dates provided: {start_date}, {end_date}\")\n","            return\n","\n","        stock_symbol = stock_symbol.replace(' ', '')\n","        link = f\"https://query2.finance.yahoo.com/v8/finance/chart/{stock_symbol}?period1={period1}&period2={period2}&interval=1m&includePrePost=true&events=div%7Csplit%7Cearnings&lang=en-US&region=US\"\n","        response = rq.get(link, headers=self.headers)\n","\n","        if response.status_code == 200:\n","            tmppath = f'/kaggle/working/per_minute_recover/json/{stock_symbol}.json'\n","            with open(tmppath, 'wb') as jsn:\n","                jsn.write(response.content)\n","            json_data = response.json()\n","\n","            try:\n","                timestamps = json_data['chart']['result'][0]['timestamp']\n","                indicators = json_data['chart']['result'][0]['indicators']['quote'][0]\n","                indicators['timestamp'] = self.return_human_timestamp(timestamps)\n","\n","                df = pd.DataFrame(indicators)\n","                os.makedirs(f'/kaggle/working/per_minute_recover/csv/{stock_symbol}/',exist_ok = True)\n","                df.to_csv(\n","                    f\"/kaggle/working/per_minute_recover/csv/{stock_symbol}/{start_date}_{end_date}.csv\",\n","                    index=False,\n","                )\n","            except KeyError as e:\n","                print(f\"Error processing JSON data: {e}\")\n","        else:\n","            print(f\"Failed to fetch data for {stock_symbol}. Status code: {response.status_code}\")\n","\n","    def setup_batches(self):\n","        today = datetime.now()\n","        while today.weekday() != 6:  # Find the latest sunday\n","            today -= timedelta(days=1)\n","        \n","        # Generate the four weeks from today (Monday to Friday)\n","        self.batches_to_check = []\n","        for i in range(4):  # Generate 4 weeks\n","            end_date = today - timedelta(weeks=i)\n","            start_date = end_date - timedelta(days=6)  # Monday\n","            self.batches_to_check.append((\n","                start_date.replace(hour=0, minute=0, second=0), \n","                end_date.replace(hour=23, minute=59, second=59)\n","            ))\n","        print(f\"Generated batches to check\")\n","    \n","    def chheck_stock_for_batch(self, symbol):   \n","        newdf = self.avdata[self.avdata['stockname'] == symbol]\n","        newdf['dates'] = pd.to_datetime(newdf['timestamp']).dt.date\n","        available_dates = set(newdf['dates'])    \n","        missing_weeks = []\n","\n","        for start_date, end_date in self.batches_to_check:\n","            # Business days: Monday to Friday\n","            week_dates = set(pd.date_range(start=start_date, end=end_date, freq='B').date)\n","            \n","            # Check if all the business days (Monday to Friday) are missing\n","            if week_dates.isdisjoint(available_dates):\n","                # print(f\"{symbol} Week {start_date} to {end_date} is entirely missing (all weekdays missing)\")\n","                # Convert start_date and end_date to Unix timestamps\n","                start_unix = int(start_date.timestamp())\n","                end_unix = int(end_date.timestamp())\n","                missing_weeks.append([symbol, start_unix, end_unix])\n","        return missing_weeks\n","\n","    def detect_all_stocks(self):\n","        all_stocks = self.avdata['stockname'].unique()\n","        self.setup_batches()  \n","        for st in tqdm(all_stocks):\n","            missing_weeks = self.chheck_stock_for_batch(st)\n","            self.recoverlist = self.recoverlist + missing_weeks\n","        print(\"setup for targets completed\")\n","        return self.recoverlist\n","\n","    def download_bunches_mass(self,targets):\n","        print(\"starting scrappers\")\n","        try:\n","            for item in tqdm(targets):\n","                self.collect_per_minute_data(item[0],item[1],item[2])\n","        except Exception as error:\n","            print(error)\n","\n","    def merge_new_data(self):\n","        newframe = pd.DataFrame()\n","        print(\"starting mergers\")\n","        all_csvs = os.listdir('/kaggle/working/per_minute_recover/csv/')\n","        for a_csv in tqdm(all_csvs):\n","            all_files = os.listdir(f'/kaggle/working/per_minute_recover/csv/{a_csv}')\n","            for a_file in all_files:\n","                tmpdf = pd.read_csv(f'/kaggle/working/per_minute_recover/csv/{a_csv}/{a_file}')\n","                tmpdf['stockname'] = a_csv.split('.')[0]\n","                newframe = pd.concat([newframe,tmpdf],axis = 0)\n","        print(\"finishing mergers\")\n","        return newframe\n","\n","    def final_merge(self,newcollecteddf):\n","        newdf = pd.concat([self.avdata,newcollecteddf])\n","        del self.avdata\n","        gc.collect()\n","        print(\"prepared new dataframe\")\n","        newdf = newdf[['stockname','timestamp','open','high','low','close','volume']]\n","        newdf.to_csv('/kaggle/working/per_minute_recover/final/stocks.csv')\n","        print(\"wrote new file\")\n","        print(\"finishing main merge\")\n","\n","    def create_metadata_to_push_recover(self):\n","        print('Creating metadata file for per minute data>>>>')\n","        data = {\n","            \"id\": \"ayushkhaire/real-time-stocks-data\"\n","        }\n","        metadata_file_location = '/kaggle/working/per_minute_recover/final/dataset-metadata.json' \n","        with open(metadata_file_location, 'w', encoding='utf-8') as metadata_file:\n","            json.dump(data, metadata_file)\n","        print('Metadata file created for per minute data')\n","\n","    def upload_recovered_to_kaggle(self):\n","        os.environ['KAGGLE_USERNAME'] = kaggle_username\n","        os.environ['KAGGLE_KEY'] = kaggle_apikey\n","        retries = 0\n","        while retries < 5:\n","            try:\n","                command = \"kaggle datasets version -p '/kaggle/working/per_minute_recover/final' -m 'Update' -r zip\"\n","                subprocess.run(command, shell=True, check=True)\n","                logger.info(\"Upload completefor per minute data\")\n","                break\n","            except Exception as error:\n","                logger.error(f\"Error from Kaggle: {error}\")\n","                time.sleep(5)\n","                retries += 1  "]},{"cell_type":"code","execution_count":7,"id":"9aa66328","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:26.743661Z","iopub.status.busy":"2025-02-23T17:12:26.743278Z","iopub.status.idle":"2025-02-23T17:12:26.748804Z","shell.execute_reply":"2025-02-23T17:12:26.747069Z"},"papermill":{"duration":0.015284,"end_time":"2025-02-23T17:12:26.751466","exception":false,"start_time":"2025-02-23T17:12:26.736182","status":"completed"},"tags":[]},"outputs":[],"source":["# ndf = RCC.avdata[RCC.avdata['stockname'] == \"PLTR\"]\n","# ndf['d'] = ndf['timestamp'].str.split(\" \").str[0]  # Extract only the date part\n","# print(ndf['d'].unique())  # Print unique dates for manual verification\n","# ndf"]},{"cell_type":"markdown","id":"230cf639","metadata":{"papermill":{"duration":0.007558,"end_time":"2025-02-23T17:12:26.765282","exception":false,"start_time":"2025-02-23T17:12:26.757724","status":"completed"},"tags":[]},"source":["# Driver code"]},{"cell_type":"code","execution_count":8,"id":"ff50cce5","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:26.779353Z","iopub.status.busy":"2025-02-23T17:12:26.778933Z","iopub.status.idle":"2025-02-23T17:12:26.785961Z","shell.execute_reply":"2025-02-23T17:12:26.784449Z"},"papermill":{"duration":0.016756,"end_time":"2025-02-23T17:12:26.78847","exception":false,"start_time":"2025-02-23T17:12:26.771714","status":"completed"},"tags":[]},"outputs":[],"source":["# make force - True when notebook fails and do not update per minute data , and give saturdday data\n","force = False"]},{"cell_type":"code","execution_count":9,"id":"c345d407","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:26.802264Z","iopub.status.busy":"2025-02-23T17:12:26.8019Z","iopub.status.idle":"2025-02-23T17:12:29.247958Z","shell.execute_reply":"2025-02-23T17:12:29.246858Z"},"papermill":{"duration":2.455701,"end_time":"2025-02-23T17:12:29.250477","exception":false,"start_time":"2025-02-23T17:12:26.794776","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["AC.delete(\"daily_data\",_del_all_ = True)\n","AC.delete(\"per_minute_data\",_del_all_ = True)"]},{"cell_type":"code","execution_count":10,"id":"5504182d","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:29.264191Z","iopub.status.busy":"2025-02-23T17:12:29.263831Z","iopub.status.idle":"2025-02-23T17:12:51.641484Z","shell.execute_reply":"2025-02-23T17:12:51.640209Z"},"papermill":{"duration":22.387466,"end_time":"2025-02-23T17:12:51.644175","exception":false,"start_time":"2025-02-23T17:12:29.256709","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n"]}],"source":["STM = stocksManager()\n","symbols = STM.collect_stock_symbols()\n","finals_symbols = []\n","for n in symbols['names']:\n","    for key in n.keys():\n","        finals_symbols=finals_symbols+n[key]\n","finals_symbols = list(set(finals_symbols))"]},{"cell_type":"code","execution_count":11,"id":"c1a94ef6","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:12:51.660183Z","iopub.status.busy":"2025-02-23T17:12:51.659787Z","iopub.status.idle":"2025-02-23T17:43:06.618362Z","shell.execute_reply":"2025-02-23T17:43:06.616955Z"},"papermill":{"duration":1814.969803,"end_time":"2025-02-23T17:43:06.621162","exception":false,"start_time":"2025-02-23T17:12:51.651359","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2170/2170 [21:56<00:00,  1.65it/s]\n","100%|██████████| 2159/2159 [06:49<00:00,  5.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["there is no monday today\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2159/2159 [00:00<00:00, 1108927.55it/s]\n"]}],"source":["STM.Kaggle_process_daily_data(finals_symbols)\n","today = datetime.now()\n","if today.weekday() == 0 or force == True:\n","    print(\"there is monday today\")\n","    yesterday = today - timedelta(days=1)\n","    yesterdays_date = yesterday.strftime('%Y-%m-%d 00:00:00')\n","    STM.Kaggle_process_per_minute_data(symbol_list = finals_symbols,last_date = yesterdays_date,weekday = 0)\n","else:\n","    print(\"there is no monday today\")\n","STM.update_stocks_list_for_today()"]},{"cell_type":"markdown","id":"df16f1c4","metadata":{"papermill":{"duration":0.228883,"end_time":"2025-02-23T17:43:07.077352","exception":false,"start_time":"2025-02-23T17:43:06.848469","status":"completed"},"tags":[]},"source":["# create metadata files"]},{"cell_type":"code","execution_count":12,"id":"3bb52e6e","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:43:07.591551Z","iopub.status.busy":"2025-02-23T17:43:07.59018Z","iopub.status.idle":"2025-02-23T17:43:07.598866Z","shell.execute_reply":"2025-02-23T17:43:07.597577Z"},"papermill":{"duration":0.302707,"end_time":"2025-02-23T17:43:07.601394","exception":false,"start_time":"2025-02-23T17:43:07.298687","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating metadata file for daily data>>>>\n","Metadata file created for daily data\n"]}],"source":["logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n"," \n","print('Creating metadata file for daily data>>>>')\n","data = {\n","    \"id\": \"ayushkhaire/stock-past-one-year-data\"\n","}\n","metadata_file_location = '/kaggle/working/daily_update_to_kaggle_final/dataset-metadata.json' \n","with open(metadata_file_location, 'w', encoding='utf-8') as metadata_file:\n","    json.dump(data, metadata_file)\n","print('Metadata file created for daily data')"]},{"cell_type":"code","execution_count":13,"id":"708da6fc","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:43:08.041181Z","iopub.status.busy":"2025-02-23T17:43:08.040779Z","iopub.status.idle":"2025-02-23T17:43:08.047767Z","shell.execute_reply":"2025-02-23T17:43:08.046228Z"},"papermill":{"duration":0.231842,"end_time":"2025-02-23T17:43:08.050353","exception":false,"start_time":"2025-02-23T17:43:07.818511","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["there is no monday today\n"]}],"source":["if today.weekday() == 0 or force == True:\n","    print('Creating metadata file for per minute data>>>>')\n","    data = {\n","        \"id\": \"ayushkhaire/real-time-stocks-data\"\n","    }\n","    metadata_file_location = '/kaggle/working/per_minute_to_kaggle_final/dataset-metadata.json' \n","    with open(metadata_file_location, 'w', encoding='utf-8') as metadata_file:\n","        json.dump(data, metadata_file)\n","    print('Metadata file created for per minute data')\n","else:\n","    print(\"there is no monday today\")"]},{"cell_type":"markdown","id":"ee2ed7b1","metadata":{"papermill":{"duration":0.236602,"end_time":"2025-02-23T17:43:08.513976","exception":false,"start_time":"2025-02-23T17:43:08.277374","status":"completed"},"tags":[]},"source":["# upload"]},{"cell_type":"code","execution_count":14,"id":"380189fa","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:43:08.970034Z","iopub.status.busy":"2025-02-23T17:43:08.969628Z","iopub.status.idle":"2025-02-23T17:43:08.97521Z","shell.execute_reply":"2025-02-23T17:43:08.973614Z"},"papermill":{"duration":0.239629,"end_time":"2025-02-23T17:43:08.978781","exception":false,"start_time":"2025-02-23T17:43:08.739152","status":"completed"},"tags":[]},"outputs":[],"source":["os.environ['KAGGLE_USERNAME'] = kaggle_username\n","os.environ['KAGGLE_KEY'] = kaggle_apikey"]},{"cell_type":"code","execution_count":15,"id":"aafb82b8","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:43:09.496439Z","iopub.status.busy":"2025-02-23T17:43:09.495986Z","iopub.status.idle":"2025-02-23T17:43:18.075046Z","shell.execute_reply":"2025-02-23T17:43:18.073136Z"},"papermill":{"duration":8.818779,"end_time":"2025-02-23T17:43:18.080767","exception":false,"start_time":"2025-02-23T17:43:09.261988","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting upload for file stocks.csv\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 520M/520M [00:06<00:00, 85.2MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: stocks.csv (520MB)\n","Dataset version is being created. Please check progress at https://www.kaggle.com/ayushkhaire/stock-past-one-year-data\n"]}],"source":["retries = 0\n","while retries < 5:\n","    try:\n","        command = \"kaggle datasets version -p '/kaggle/working/daily_update_to_kaggle_final' -m 'Update' -r zip\"\n","        subprocess.run(command, shell=True, check=True)\n","        logger.info(\"Upload completefor daily data\")\n","        break\n","    except Exception as error:\n","        logger.error(f\"Error from Kaggle: {error}\")\n","        time.sleep(5)\n","        retries += 1"]},{"cell_type":"code","execution_count":16,"id":"8a7fc71d","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:43:18.771829Z","iopub.status.busy":"2025-02-23T17:43:18.771087Z","iopub.status.idle":"2025-02-23T17:43:18.782197Z","shell.execute_reply":"2025-02-23T17:43:18.780772Z"},"papermill":{"duration":0.345345,"end_time":"2025-02-23T17:43:18.785325","exception":false,"start_time":"2025-02-23T17:43:18.43998","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["there is no saturday today\n"]}],"source":["if today.weekday() == 0 or force == True:\n","    print(\"there is monday today\")    \n","    retries = 0\n","    while retries < 5:\n","        try:\n","            command = \"kaggle datasets version -p '/kaggle/working/per_minute_to_kaggle_final' -m 'Update' -r zip\"\n","            subprocess.run(command, shell=True, check=True)\n","            logger.info(\"Upload completefor per minute data\")\n","            break\n","        except Exception as error:\n","            logger.error(f\"Error from Kaggle: {error}\")\n","            time.sleep(5)\n","            retries += 1\n","else:\n","    print(\"there is no saturday today\")    "]},{"cell_type":"markdown","id":"fab65d0f","metadata":{"papermill":{"duration":0.279411,"end_time":"2025-02-23T17:43:19.368832","exception":false,"start_time":"2025-02-23T17:43:19.089421","status":"completed"},"tags":[]},"source":["# Recover lost one"]},{"cell_type":"code","execution_count":17,"id":"1658abc7","metadata":{"execution":{"iopub.execute_input":"2025-02-23T17:43:20.01074Z","iopub.status.busy":"2025-02-23T17:43:20.01004Z","iopub.status.idle":"2025-02-23T19:16:11.00158Z","shell.execute_reply":"2025-02-23T19:16:10.999879Z"},"papermill":{"duration":5571.353623,"end_time":"2025-02-23T19:16:11.004755","exception":false,"start_time":"2025-02-23T17:43:19.651132","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["set up directories\n","stock list and dataset loaded .\n","Generated batches to check\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 606/606 [1:10:01<00:00,  6.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["setup for targets completed\n","starting scrappers\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 733/3665 [02:36<08:10,  5.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Error processing JSON data: 'timestamp'\n","Error processing JSON data: 'timestamp'\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 735/3665 [02:36<06:44,  7.24it/s]"]},{"name":"stdout","output_type":"stream","text":["Error processing JSON data: 'timestamp'\n","Error processing JSON data: 'timestamp'\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 1338/3665 [04:38<05:48,  6.68it/s]"]},{"name":"stdout","output_type":"stream","text":["Error processing JSON data: 'timestamp'\n","Error processing JSON data: 'timestamp'\n","Error processing JSON data: 'timestamp'\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 1341/3665 [04:38<05:10,  7.48it/s]"]},{"name":"stdout","output_type":"stream","text":["Error processing JSON data: 'timestamp'\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 1508/3665 [05:11<05:08,  7.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Failed to fetch data for S. Status code: 400\n","Failed to fetch data for R. Status code: 400\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 1511/3665 [05:11<04:23,  8.16it/s]"]},{"name":"stdout","output_type":"stream","text":["Failed to fetch data for A. Status code: 400\n","Failed to fetch data for P. Status code: 400\n","Failed to fetch data for B. Status code: 400\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████▏     | 1513/3665 [05:11<04:02,  8.86it/s]"]},{"name":"stdout","output_type":"stream","text":["Failed to fetch data for D. Status code: 400\n","Failed to fetch data for D. Status code: 400\n","Failed to fetch data for I. Status code: 400\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████▏     | 1516/3665 [05:11<07:22,  4.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Failed to fetch data for N. Status code: 400\n","Failed to fetch data for C. Status code: 400\n","string index out of range\n","starting mergers\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 306/306 [01:30<00:00,  3.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["finishing mergers\n","prepared new dataframe\n","wrote new file\n","finishing main merge\n","Creating metadata file for per minute data>>>>\n","Metadata file created for per minute data\n","Starting upload for file stocks.csv\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 7.48G/7.48G [01:32<00:00, 86.9MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: stocks.csv (7GB)\n","Dataset version is being created. Please check progress at https://www.kaggle.com/ayushkhaire/real-time-stocks-data\n"]}],"source":["RCC = recoverData()\n","RCC.setup()\n","targets = RCC.detect_all_stocks()\n","targets = targets + STM.available_stocks\n","RCC.download_bunches_mass(targets)\n","newcollecteddf = RCC.merge_new_data()\n","RCC.final_merge(newcollecteddf)\n","RCC.create_metadata_to_push_recover()\n","RCC.upload_recovered_to_kaggle()"]},{"cell_type":"code","execution_count":18,"id":"74576db7","metadata":{"execution":{"iopub.execute_input":"2025-02-23T19:16:11.847237Z","iopub.status.busy":"2025-02-23T19:16:11.84682Z","iopub.status.idle":"2025-02-23T19:16:12.09812Z","shell.execute_reply":"2025-02-23T19:16:12.09691Z"},"papermill":{"duration":0.636799,"end_time":"2025-02-23T19:16:12.100549","exception":false,"start_time":"2025-02-23T19:16:11.46375","status":"completed"},"tags":[]},"outputs":[],"source":["shutil.rmtree('/kaggle/working/daily_update')\n","shutil.rmtree('/kaggle/working/daily_update_to_kaggle')\n","if today.weekday() == 0 or force == True:\n","    shutil.rmtree('/kaggle/working/per_minute')\n","    shutil.rmtree('/kaggle/working/per_minute_to_kaggle')\n","    shutil.rmtree('/kaggle/working/per_minute_recover')\n","    shutil.rmtree('/kaggle/working/per_minute_to_kaggle_final')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4987536,"sourceId":10767740,"sourceType":"datasetVersion"},{"datasetId":5902635,"sourceId":10768018,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":7434.688908,"end_time":"2025-02-23T19:16:13.907196","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-23T17:12:19.218288","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}